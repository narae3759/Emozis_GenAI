import streamlit as st 
from core.utils import *

setting()

# llm ê´€ë ¨
from pathlib import Path 
from langchain_openai import ChatOpenAI 
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain.memory import ConversationBufferMemory
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from operator import itemgetter

from google.api_core import exceptions
#-------------------------------------------------------------------
# Settings
#-------------------------------------------------------------------
key_expander = "isexpanded"
key_chain = "demo_chain"
key_memory = "demo_memory"
key_history = "demo_history"

def fold_container():
    st.session_state[key_expander] = False

if not key_expander in st.session_state:
    st.session_state[key_expander] = True

if "page" not in st.session_state:
    st.session_state["page"] = 1

def start_chat(data):
    st.session_state["chat_character"] = data
    st.session_state["page"] = 2

def end_chat():
    st.session_state["chat_character"] = None
    del st.session_state[key_history]
    del st.session_state[key_memory]
    del st.session_state[key_chain]
    st.session_state["page"] = 1
#-------------------------------------------------------------------
# Header
#-------------------------------------------------------------------
import requests 
import json 
url = "http://172.16.2.10:8000/character"
response = requests.get(url)
if response.status_code == 200:
    data = {i:x for i, x in enumerate(json.loads(response.text)["data"],1)}
else:
    print("NO")

if st.session_state["page"] == 1:
    # 2í–‰ì˜ ì—´ êµ¬ì„±: ê° í–‰ì— 4ê°œì˜ ì—´ì„ ìƒì„±
    cols = st.columns(4)

    # ê° ì—´ì— ë²„íŠ¼ ì¶”ê°€
    for key, element in data.items():
        # i % 4ëŠ” í˜„ì¬ ë²„íŠ¼ì´ ì–´ë–¤ ì—´ì— ì†í•˜ëŠ”ì§€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤ (0ë¶€í„° 3ê¹Œì§€ì˜ ì¸ë±ìŠ¤)
        col = cols[key % 4]
        
        with col:
            with st.container(border=True):
                st.image(element["profile"])
                st.markdown(element["name"])
                st.button(
                    label="ì±„íŒ…í•˜ê¸°", 
                    key=key, 
                    use_container_width=True, 
                    on_click=start_chat,
                    args=[data[key]])


elif st.session_state["page"] == 2:
    st.button("ë’¤ë¡œê°€ê¸°", on_click=end_chat)
    #-------------------------------------------------------------------
    # Sidebar
    #-------------------------------------------------------------------
    with st.sidebar:
        data = st.session_state["chat_character"]
        columns = st.columns(spec=[0.3,0.4,0.3])
        with columns[1]:
            st.image(data["profile"])
        st.markdown(f"ì´ë¦„: {data['name']}")
        st.markdown(f"ì„±ê²©: {data['personality']}")
        st.write(f"ìƒì„¸ì„¤ëª…:\n ...")
    #-------------------------------------------------------------------
    # Make Chain
    #-------------------------------------------------------------------
    # ì±„íŒ…ì„ ì´ì–´ë‚˜ê°ˆ ë•Œ
    if key_chain in st.session_state:
        chain = st.session_state[key_chain]
        memory = st.session_state[key_memory]
        history = st.session_state[key_history]
    # ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ì ìš©í•  ë•Œ
    else:
        # ì´ˆê¸°í™” 
        st.session_state[key_history] = []

        # ë©”ëª¨ë¦¬ ì„¤ì •
        memory = ConversationBufferMemory(
            return_messages=True, 
            memory_key="chat_history"
        )
        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        # template = read_prompt("./static/templates/Demo.prompt")
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", data["details"]),
                MessagesPlaceholder(variable_name="chat_history"),
                ("human", "{input}"),
            ]
        )
        # ì²´ì¸ ë§Œë“¤ê¸°
        runnable = RunnablePassthrough.assign(
            chat_history = RunnableLambda(memory.load_memory_variables)
            | itemgetter("chat_history")
        )
        model = ChatOpenAI(model_name="gpt-3.5-turbo")
        output_parser = StrOutputParser()
        runnable = RunnablePassthrough.assign(
                chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter("chat_history")
            )
        chain = runnable | prompt | model | StrOutputParser()
        # ì„¸ì…˜ ì •ë³´ ì €ì¥
        st.session_state[key_chain] = chain
        st.session_state[key_memory] = memory
    #-------------------------------------------------------------------
    # Chat Messages
    #-------------------------------------------------------------------
    # ì²« ì±„íŒ…ì„ ì‹œì‘í•  ë•Œ ì²« ì¸ì‚¬ ì¶œë ¥
    if len(st.session_state[key_history]) == 0:
        greeting = "ì•ˆë…•í•˜ì„¸ìš”ğŸ˜‹"
        st.chat_message("assistant").markdown(greeting)
        st.session_state[key_history].append(
            {"role":"assistant", "content": greeting}
        )
    # ì±„íŒ… ê¸°ë¡ì´ ìˆì„ ë•Œ ê¸°ë¡ëœ ì±„íŒ… ì¶œë ¥
    else:
        for chat in st.session_state[key_history]:
            st.chat_message(chat["role"]).markdown(chat["content"])

    # ì±„íŒ…ì°½ ì…ë ¥
    question = st.chat_input(placeholder="ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    if question:
        # ì…ë ¥ëœ ì±„íŒ… ì¶œë ¥
        st.chat_message("user").markdown(question)
        st.session_state[key_history].append(
            {"role":"user", "content":question}
        )
        # ë‹µë³€ ì¶œë ¥
        with st.chat_message("assistant"):
            container = st.empty()
            answer = ""
            inputs = {
                "input": question
            }
            # print(chain)
            
            for token in chain.stream(inputs):
                answer += token
                container.markdown(answer)
        
        st.session_state[key_history].append(
            {"role":"assistant", "content":answer}
        )
        # ë©”ëª¨ë¦¬ ì €ì¥
        memory.save_context(
            {"inputs": question},
            {"output": answer}
        )

        # ë©”ëª¨ë¦¬ ì¶œë ¥
        # print(memory.load_memory_variables({}))
